{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\julia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\julia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\julia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\julia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from math import log\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(['punkt','stopwords','wordnet','words'])\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import metapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('estructuraDatos.sav', 'rb'))\n",
    "idexFiles = loaded_model['idexFiles']\n",
    "vectorizer = loaded_model['vectorizer']\n",
    "matrix = loaded_model['matriz']\n",
    "indexMeta = loaded_model['metapyIndex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encontrar los documentos que contiene una palabra en particular\n",
    "def encontrarDoc(palabra):\n",
    "    col = vectorizer.vocabulary_[palabra]\n",
    "    matx = matrix[:,col]\n",
    "    indx = matx.nonzero()[0]\n",
    "    lista =indx.tolist() \n",
    "    dfresult = pd.DataFrame()\n",
    "    for i in range(len(lista)):\n",
    "        auxres= pd.DataFrame({'NombreArchivo': idexFiles[lista[i]], 'Frecuencia': [matx.data[i]]})\n",
    "        dfresult = pd.concat([dfresult, auxres])\n",
    "    dfresult.sort_values('Frecuencia',ascending = False,inplace = True)\n",
    "    return dfresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indice_invertido(dic):\n",
    "    inv = {}\n",
    "    N = matrix.shape[0]\n",
    "    for k, v in vectorizer.vocabulary_.items():\n",
    "        inv.setdefault(k, {})\n",
    "        #Los documentos que contienen la palabra v\n",
    "        matx = matrix[:,v]\n",
    "        #Indicador de los documentos que contienen la palabra\n",
    "        indx = matx.nonzero()[0]\n",
    "        lista =indx.tolist()\n",
    "        docs = {}\n",
    "        if len(lista)== 0:\n",
    "            print(k)\n",
    "        else:\n",
    "            #Calculo del IDF, lista contiene todos los documentos que contienen la palabra\n",
    "            inv[k]['IDF'] = log((N+1)/(len(lista)))\n",
    "            for i in range(len(lista)):\n",
    "                keys = docs.setdefault(idexFiles[lista[i]], [])\n",
    "                #Frecuencia de la palabra V en el documento lista[i]\n",
    "                keys.append(matx.data[i])\n",
    "                #Las palabras que contiene el documento lista[i]\n",
    "                matx2 = matrix[lista[i],:]\n",
    "                #La frecuencia de cada palabra, que sumada el vector da el total de palabras en el documento\n",
    "                keys.append(matx2.data.sum())\n",
    "        inv[k]['Documentos'] = docs\n",
    "    return inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "across\n",
      "all\n",
      "almost\n",
      "along\n",
      "also\n",
      "amount\n",
      "an\n",
      "anyhow\n",
      "anyway\n",
      "around\n",
      "as\n",
      "at\n",
      "b\n",
      "back\n",
      "be\n",
      "beforehand\n",
      "behind\n",
      "beyond\n",
      "bill\n",
      "bottom\n",
      "c\n",
      "call\n",
      "co\n",
      "con\n",
      "d\n",
      "de\n",
      "detail\n",
      "do\n",
      "down\n",
      "due\n",
      "e\n",
      "eight\n",
      "either\n",
      "eleven\n",
      "enough\n",
      "even\n",
      "ever\n",
      "except\n",
      "f\n",
      "few\n",
      "fifteen\n",
      "fill\n",
      "find\n",
      "fire\n",
      "first\n",
      "five\n",
      "former\n",
      "four\n",
      "front\n",
      "full\n",
      "further\n",
      "g\n",
      "get\n",
      "give\n",
      "go\n",
      "h\n",
      "he\n",
      "herein\n",
      "i\n",
      "ie\n",
      "in\n",
      "inc\n",
      "interest\n",
      "j\n",
      "k\n",
      "keep\n",
      "l\n",
      "last\n",
      "latter\n",
      "least\n",
      "m\n",
      "may\n",
      "might\n",
      "mill\n",
      "mine\n",
      "move\n",
      "much\n",
      "must\n",
      "n\n",
      "name\n",
      "neither\n",
      "never\n",
      "nevertheless\n",
      "next\n",
      "nine\n",
      "none\n",
      "o\n",
      "off\n",
      "often\n",
      "on\n",
      "one\n",
      "or\n",
      "out\n",
      "own\n",
      "p\n",
      "part\n",
      "put\n",
      "q\n",
      "r\n",
      "rather\n",
      "re\n",
      "s\n",
      "same\n",
      "see\n",
      "seem\n",
      "serious\n",
      "show\n",
      "side\n",
      "six\n",
      "so\n",
      "somehow\n",
      "still\n",
      "system\n",
      "t\n",
      "take\n",
      "ten\n",
      "there\n",
      "therein\n",
      "these\n",
      "thick\n",
      "thin\n",
      "third\n",
      "though\n",
      "three\n",
      "throughout\n",
      "top\n",
      "two\n",
      "u\n",
      "un\n",
      "up\n",
      "us\n",
      "v\n",
      "w\n",
      "well\n",
      "whole\n",
      "will\n",
      "with\n",
      "within\n",
      "x\n",
      "y\n",
      "yet\n",
      "z\n"
     ]
    }
   ],
   "source": [
    "ind_inv = indice_invertido(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopWords = stopwords.words('english')\n",
    "def queryClean(texto):\n",
    "    #Pasar todo a minisculas\n",
    "    texto = texto.lower()\n",
    "    texto =re.sub('(á|à|ä)','a',texto) # Reemplazar a acentuada\n",
    "    texto =re.sub('(é|è|ë)','e',texto) # Reemplazar e acentuada\n",
    "    texto =re.sub('(í|ì|ï)','i',texto) # Reemplazar i acentuada\n",
    "    texto =re.sub('(ó|ò|ö)','o',texto) # Reemplazar o acentuada\n",
    "    texto =re.sub('(ú|ù|ü)','u',texto) # Reemplazar u acentuada\n",
    "    texto =re.sub('[^a-zA-Z]',' ',texto) # Eliminar caracteres que no sean: letra, número o vocales acentuadas\n",
    "    texto =re.sub(' +',' ',texto) # Eliminar espacios en blanco\n",
    "    #Tokenizar\n",
    "    tokens = texto.split()\n",
    "    tokens = [w for w in tokens if (len(w)>1)&(w.isalpha())&(w not in stopWords)]\n",
    "    #Lemma\n",
    "    word_net_lemmatizar = WordNetLemmatizer()\n",
    "    tokens = [word_net_lemmatizar.lemmatize(w, pos = \"v\") for w in tokens]\n",
    "\n",
    "    #Stemmer\n",
    "    ps = PorterStemmer() \n",
    "    tokens = [ps.stem(w) for w in tokens]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Rankin por Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryTF(word,top):\n",
    "    respuesta = sorted(ind_inv[word]['Documentos'].items(), key = lambda kv:(kv[1], kv[0]),reverse=True)\n",
    "    return respuesta[0:top]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rankin por Term Frequency / Doc Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryTFDL(word,top):\n",
    "    aux = ind_inv[word]['Documentos']\n",
    "    auxdic = {}\n",
    "    for k,v in aux.items():\n",
    "        keys = auxdic.setdefault(k, [])\n",
    "        keys.append(v[0]/v[1])\n",
    "    respuesta = sorted(auxdic.items(), key = lambda kv:(kv[1], kv[0]),reverse=True)\n",
    "    return respuesta[0:top]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rankin usando BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_bm25(idf,frec,k,b,length,avgdl):\n",
    "    aux = idf*((frec*(k+1))/(frec+k*(1-b+b*length/avgdl)))\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryBM25(query, vocabulary, prom, k1, b, top):\n",
    "    query_word = queryClean(query)\n",
    "    dfresultb25 = pd.DataFrame()\n",
    "    resultadoBm25 = pd.DataFrame()\n",
    "    for word in query_word:\n",
    "        if (word in vocabulary):\n",
    "            aux = ind_inv[word]['Documentos']\n",
    "            IDF = ind_inv[word]['IDF']\n",
    "            for k,v in aux.items():\n",
    "            #     keys = bm25.setdefault(k, [])\n",
    "                aux25 = cal_bm25(IDF,v[0],k1,b,v[1],prom)\n",
    "                auxresb25= pd.DataFrame({'NombreArchivo': k.split('\\\\')[-1], 'Word': word, 'BM25' : [aux25]})\n",
    "                dfresultb25 = pd.concat([dfresultb25, auxresb25])\n",
    "            resultadoBm25 = dfresultb25.groupby('NombreArchivo').agg({'BM25':'sum'}).sort_values('BM25',ascending = False).reset_index()\n",
    "            resultadoBm25.reset_index(inplace = True)\n",
    "            resultadoBm25.rename(columns = {'index':'Ranking'}, inplace = True)\n",
    "        else:\n",
    "            print(f'{word} is not in the vocabulary')\n",
    "    return resultadoBm25.head(top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición de parámetros para el BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = 20\n",
    "prom = 27544.226762002043\n",
    "k1 = 1.2\n",
    "b = 0.75\n",
    "vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\"machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = 20\n",
    "prom = 27544.226762002043\n",
    "k1 = 1.2\n",
    "b = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = queryBM25(query, vocabulary, prom, k1, b,top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>NombreArchivo</th>\n",
       "      <th>BM25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1502.05767.txt</td>\n",
       "      <td>4.289243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1306.3726.txt</td>\n",
       "      <td>4.289187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1511.01258.txt</td>\n",
       "      <td>4.282112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1206.4656.txt</td>\n",
       "      <td>4.281008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1312.0049.txt</td>\n",
       "      <td>4.279830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1503.01239.txt</td>\n",
       "      <td>4.270601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1401.1061.txt</td>\n",
       "      <td>4.269371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1506.01110.txt</td>\n",
       "      <td>4.266588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1508.01993.txt</td>\n",
       "      <td>4.261827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1506.03410.txt</td>\n",
       "      <td>4.257082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1503.08381.txt</td>\n",
       "      <td>4.255335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1411.5878.txt</td>\n",
       "      <td>4.249178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1502.07209.txt</td>\n",
       "      <td>4.243498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1307.7050.txt</td>\n",
       "      <td>4.242264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1411.0440.txt</td>\n",
       "      <td>4.238486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1502.06464.txt</td>\n",
       "      <td>4.237889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1408.0848.txt</td>\n",
       "      <td>4.237827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1502.05472.txt</td>\n",
       "      <td>4.229062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1307.8371.txt</td>\n",
       "      <td>4.227998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1006.1029.txt</td>\n",
       "      <td>4.226565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ranking   NombreArchivo      BM25\n",
       "0         0  1502.05767.txt  4.289243\n",
       "1         1   1306.3726.txt  4.289187\n",
       "2         2  1511.01258.txt  4.282112\n",
       "3         3   1206.4656.txt  4.281008\n",
       "4         4   1312.0049.txt  4.279830\n",
       "5         5  1503.01239.txt  4.270601\n",
       "6         6   1401.1061.txt  4.269371\n",
       "7         7  1506.01110.txt  4.266588\n",
       "8         8  1508.01993.txt  4.261827\n",
       "9         9  1506.03410.txt  4.257082\n",
       "10       10  1503.08381.txt  4.255335\n",
       "11       11   1411.5878.txt  4.249178\n",
       "12       12  1502.07209.txt  4.243498\n",
       "13       13   1307.7050.txt  4.242264\n",
       "14       14   1411.0440.txt  4.238486\n",
       "15       15  1502.06464.txt  4.237889\n",
       "16       16   1408.0848.txt  4.237827\n",
       "17       17  1502.05472.txt  4.229062\n",
       "18       18   1307.8371.txt  4.227998\n",
       "19       19   1006.1029.txt  4.226565"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_idx = metapy.index.make_inverted_index(\"./build/config.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_idx.num_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78549"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_idx.unique_terms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4215.095703125"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_idx.avg_doc_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4130794"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_idx.total_corpus_terms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = metapy.index.OkapiBM25()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = metapy.index.Document()\n",
    "query.content(\"machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/papers_own_impl/1206.4656.txt 4.202898979187012\n",
      "../data/papers_own_impl/1306.3726.txt 4.180741310119629\n",
      "../data/papers_own_impl/1502.05767.txt 4.1764373779296875\n",
      "../data/papers_own_impl/1201.0490.txt 4.150365352630615\n",
      "../data/papers_own_impl/1508.01993.txt 4.1466217041015625\n",
      "../data/papers_own_impl/1506.01110.txt 4.142436504364014\n",
      "../data/papers_own_impl/1312.0049.txt 4.140744209289551\n",
      "../data/papers_own_impl/1307.7050.txt 4.118325233459473\n",
      "../data/papers_own_impl/1401.1061.txt 4.1002044677734375\n",
      "../data/papers_own_impl/1503.08381.txt 4.0904083251953125\n",
      "../data/papers_own_impl/1506.03410.txt 4.069889545440674\n",
      "../data/papers_own_impl/1505.05451.txt 4.065674781799316\n",
      "../data/papers_own_impl/1507.01239.txt 4.05823278427124\n",
      "../data/papers_own_impl/1408.0848.txt 4.054011821746826\n",
      "../data/papers_own_impl/1006.1029.txt 4.051542282104492\n",
      "../data/papers_own_impl/1502.07209.txt 4.050348281860352\n",
      "../data/papers_own_impl/1511.06382.txt 4.043100833892822\n",
      "../data/papers_own_impl/1502.05472.txt 4.041956901550293\n",
      "../data/papers_own_impl/1309.3699.txt 4.032342910766602\n",
      "../data/papers_own_impl/1404.3368.txt 4.024459362030029\n"
     ]
    }
   ],
   "source": [
    "top_docs = ranker.score(inv_idx, query, num_results=20)\n",
    "for [id,r] in top_docs:\n",
    "    print(inv_idx.label(id),r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankerMeta(top, querywords):\n",
    "    ranker = metapy.index.OkapiBM25(k1 = k1, b = b)\n",
    "    query = metapy.index.Document()\n",
    "    query.content(querywords) # query from AP news\n",
    "    top_docs = ranker.score(inv_idx, query, num_results=top)\n",
    "    metaresult = pd.DataFrame()\n",
    "    for doc in top_docs:\n",
    "        auxmeta= pd.DataFrame({'NombreArchivo': indexMeta[doc[0]],  'BM25_Meta' : [doc[1]]})\n",
    "        metaresult = pd.concat([metaresult, auxmeta])\n",
    "    metaresult = metaresult.reset_index(drop = True).reset_index()\n",
    "    metaresult.rename(columns = {'index':'RankingMeta'},inplace = True)\n",
    "    return metaresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sens(queries,top):\n",
    "    sens = pd.DataFrame()\n",
    "    for query in queries:\n",
    "        resultados = queryBM25(query, vocabulary, prom, k1, b,top)\n",
    "        metares = rankerMeta(top, query)\n",
    "        merget = resultados.merge(metares, how = 'left', on = 'NombreArchivo')\n",
    "        sensibilidad = (merget['RankingMeta']>=0).sum()/len(merget)\n",
    "        auxsens= pd.DataFrame({'Query': query,  'Sensibilidad' : [sensibilidad]})\n",
    "        sens = pd.concat([sens, auxsens])\n",
    "    return sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"Data Science\",\"Machine Learning\",\"Computer Science\",\"Algorithms in dynamic networks\", \"triangle free process\",\"biology\"]\n",
    "sensibilidad = calculate_sens(queries,top)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Sensibilidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Computer Science</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Algorithms in dynamic networks</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>triangle free process</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biology</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Query  Sensibilidad\n",
       "0                    Data Science          0.65\n",
       "0                Machine Learning          0.70\n",
       "0                Computer Science          0.40\n",
       "0  Algorithms in dynamic networks          0.75\n",
       "0           triangle free process          0.50\n",
       "0                         biology          0.70"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensibilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Data Science\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = queryBM25(query, vocabulary, prom, k1, b,top)\n",
    "metares = rankerMeta(top, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>NombreArchivo</th>\n",
       "      <th>BM25</th>\n",
       "      <th>RankingMeta</th>\n",
       "      <th>BM25_Meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1509.02900.txt</td>\n",
       "      <td>1.881402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.595062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1506.00768.txt</td>\n",
       "      <td>1.875594</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.583507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1503.06483.txt</td>\n",
       "      <td>1.873385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.598270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1503.01239.txt</td>\n",
       "      <td>1.872566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1408.0135.txt</td>\n",
       "      <td>1.870710</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.582700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1412.5902.txt</td>\n",
       "      <td>1.870023</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.565338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1308.0776.txt</td>\n",
       "      <td>1.862415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1504.05895.txt</td>\n",
       "      <td>1.859011</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.557693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1407.5117.txt</td>\n",
       "      <td>1.857507</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.584339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1502.05767.txt</td>\n",
       "      <td>1.851488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1511.03518.txt</td>\n",
       "      <td>1.850348</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.551385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1306.3261.txt</td>\n",
       "      <td>1.850088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1411.0440.txt</td>\n",
       "      <td>1.848182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1411.7895.txt</td>\n",
       "      <td>1.844947</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.535604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1401.1333.txt</td>\n",
       "      <td>1.844052</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.567438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1402.6208.txt</td>\n",
       "      <td>1.842901</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.572057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1511.02476.txt</td>\n",
       "      <td>1.839631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1411.3140.txt</td>\n",
       "      <td>1.839340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1210.2246.txt</td>\n",
       "      <td>1.839154</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.544231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1503.00245.txt</td>\n",
       "      <td>1.836845</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.562056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ranking   NombreArchivo      BM25  RankingMeta  BM25_Meta\n",
       "0         0  1509.02900.txt  1.881402          1.0   1.595062\n",
       "1         1  1506.00768.txt  1.875594          3.0   1.583507\n",
       "2         2  1503.06483.txt  1.873385          0.0   1.598270\n",
       "3         3  1503.01239.txt  1.872566          NaN        NaN\n",
       "4         4   1408.0135.txt  1.870710          4.0   1.582700\n",
       "5         5   1412.5902.txt  1.870023          7.0   1.565338\n",
       "6         6   1308.0776.txt  1.862415          NaN        NaN\n",
       "7         7  1504.05895.txt  1.859011          9.0   1.557693\n",
       "8         8   1407.5117.txt  1.857507          2.0   1.584339\n",
       "9         9  1502.05767.txt  1.851488          NaN        NaN\n",
       "10       10  1511.03518.txt  1.850348         11.0   1.551385\n",
       "11       11   1306.3261.txt  1.850088          NaN        NaN\n",
       "12       12   1411.0440.txt  1.848182          NaN        NaN\n",
       "13       13   1411.7895.txt  1.844947         18.0   1.535604\n",
       "14       14   1401.1333.txt  1.844052          6.0   1.567438\n",
       "15       15   1402.6208.txt  1.842901          5.0   1.572057\n",
       "16       16  1511.02476.txt  1.839631          NaN        NaN\n",
       "17       17   1411.3140.txt  1.839340          NaN        NaN\n",
       "18       18   1210.2246.txt  1.839154         15.0   1.544231\n",
       "19       19  1503.00245.txt  1.836845          8.0   1.562056"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados.merge(metares, how = 'left', on = 'NombreArchivo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
